优化点: 批量解码与函数调用开销减少
=================================

1. 基准记录 (Baseline):
   解码吞吐: 4142.784 MB/s
   编码吞吐: 376.834 MB/s

2. 优化方案:
   观察到在原有的 Benchmark (`decode_all`) 中，解码器对每一个压缩后的字符串片段都会单独调用一次 `decode`。
   如果数据包含大量小字符串，`decode` 函数内部的 `reserve`、`set_len` 以及循环初始化开销会变得非常显著。
   由于 FSST 是无状态的，可以将所有压缩后的片段作为一个大 Batch 传入 `decode` 进行一次性解码。

3. 回归测试结果:
   解码吞吐: 6640.600 MB/s (+60.3%)
   编码吞吐: 372.860 MB/s (-1.0%)

4. 总结:
   解码性能获得了 60% 以上的爆炸性提升。这证明了在极高性能场景下，函数调用链和微小的初始化代码 (reserve/set_len) 也是不可忽视的瓶颈。
   当前的解码吞吐已达到 ~6.6 GB/s，在大容量内存访问场景下已经非常接近单核计算和访存的均衡点。
