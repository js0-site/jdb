JDB 项目愿景与边界

1. 项目愿景

打造面向 NVMe 时代的、支持海量设备、历史回溯及混合负载的 Rust 嵌入式时序存储内核。

JDB 旨在为物联网网关、边缘计算节点及工业数据采集系统提供底层的核心存储能力。它利用 Rust 语言的安全特性与 Compio 的全异步 IO 模型，深度挖掘多核 CPU 与 NVMe SSD 的硬件潜力，在单机环境下实现亿级表管理、微秒级读写延迟、全量的历史数据版本控制，并能高效吞吐大尺寸载荷数据。

2. 核心定位

形态：嵌入式动态库。JDB 不提供独立的后台进程，而是以 Rust Crate 形式直接编译链接入宿主应用程序，函数调用即数据库操作，消除进程间通信与网络开销。

模型：混合时序模型 (Hybrid Time_Series)。

继承“超级表/子表/标签”的三层结构。

支持 KV 分离架构：既能处理高频的小指标数据（Metrics），也能高效存储低频的大对象数据（Blobs），并原生支持 MVCC（多版本并发控制）。

硬件假设：现代全固态架构。所有设计均假定运行在 NVMe SSD 之上，放弃对机械硬盘寻道时间的优化，专注于高并发随机读写与高吞吐顺序扫描。

3. 核心功能范围
3.1 亿级海量表支持

必须支持单机 1 亿以上 活跃子表（设备）。

内存零元数据：内存中严禁维护子表对象，通过算法路由（Algorithmic ID）直接计算存储位置，彻底解决海量小表带来的元数据内存膨胀问题。

3.2 极致异步 I/O

基于 compio 运行时实现全链路异步化。

Thread_per_Core 架构：采用 VNode（虚拟节点）分片与无锁化设计，确保 CPU 核心间无竞争。

Direct I/O：强制绕过操作系统 Page Cache，由 JDB 自行管理用户态缓存池与对齐写入，避免双重缓存。

3.3 双引擎存储架构

TS 引擎（时序数据 _ KV 分离设计）：

索引层 (Index)：采用 B+ 树 结构，仅存储 Key 和指向 Value 的指针（Offset/Size）。保持索引极度紧凑，尽可能驻留内存。

数据层 (Value Log)：

Small Value (Metrics)：直接内联存储在 B+ 树叶子节点的列式块中，追求极致压缩与扫描速度。

Large Value (Blobs)：支持 Key_Value 分离存储（类似 WiscKey/Titan）。大对象（如波形、日志、图片）存储在独立的 Value Log 文件中，避免大对象分裂导致 B+ 树频繁重组与写放大。

MVCC 支持：采用追加写模式，通过版本号后缀保留数据修改历史，支持查询特定深度的历史快照。

Tag 引擎（标签索引）：

基于 LSM 树与 Roaring Bitmap 构建倒排索引。

支持通过标签组合（AND/OR/NOT）毫秒级定位目标设备 ID 集合。

3.4 资源与版本管理

冷却驱逐：实现基于访问频率的内存页冷却算法，严格限制内存占用上限，防止 OOM。

历史版本合并：后台自动执行 Compaction（数据压缩与整理），根据配置的“最大版本深度”合并过旧的历史数据版本和无效的大对象引用，释放物理空间。

4. 关键假设与技术约束

查询特征：

Blob 查询：高吞吐 IO 流式读取（支持异步 Stream 返回）。

数据一致性：保证单次批处理写入的原子性（Atomicity）与持久性（Durability）。即便是 KV 分离存储，也必须保证 Index 与 Value Log 的原子一致性（要么都可见，要么都不可见）。